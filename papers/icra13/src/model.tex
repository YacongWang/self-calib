\subsection{Problem Formulation\label{subsec:prob}}

In the following, we outline our problem in a probabilistic manner, closely
following the discrete-time Simultaneous Localization and Mapping (SLAM)
formulation~\cite{durrantwhyte06simultaneous}. For the sake of clarity, we
consider here a robot with a single sensor observing a known number of landmarks
at each timestep. Furthermore, we assume the correspondences between sensor's
measurements and landmarks are known. The relaxation of these assumptions goes
beyond the scope of this paper.

Let
$\mathcal{X}=\{\mathbf{x}_{0:K}\}$ be a set of \emph{latent} random variables
(LRV) representing robot states up to timestep $K$,
$\mathcal{U}=\{\mathbf{u}_{1:K}\}$ a set of \emph{observable} random variables
(ORV) representing measured control inputs, $\mathcal{L}=\{\mathbf{l}_{1:N}\}$ a
set of LRV representing $N$ landmarks' positions,
$\mathcal{Z}=\{\mathbf{z}_{1_{1:N}:K_{1:N}}\}$ a set of ORV representing $KxN$
landmarks' measurements, and $\boldsymbol{\Theta}$ a LRV representing the
calibration parameters of the robot's sensor. The goal of the calibration
procedure is to compute the posterior marginal distribution of
$\boldsymbol{\Theta}$ given all the measurements up to timestep $K$

\begin{equation}\label{eqn:post_calib}
  \begin{aligned}
  p(\boldsymbol{\Theta}\mid\mathcal{U},\mathcal{Z}) &=
    \int_{\mathcal{X}, \mathcal{L}}p(\boldsymbol{\Theta}, \mathcal{X},
    \mathcal{L} \mid\mathcal{U},\mathcal{Z}).
  \end{aligned}
\end{equation}

The full joint posterior on the left-hand side of \eqref{eqn:post_calib} may
further be factorized into

\begin{equation}\label{eqn:post_joint_factorized}
  \begin{aligned}
  p(\boldsymbol{\Theta}, \mathcal{X},
    \mathcal{L} \mid\mathcal{U},\mathcal{Z}) &\propto\\
    p(\boldsymbol{\Theta}, \mathbf{x}_0,\mathcal{L})
    \prod_{k=1}^K p(\mathbf{x}_k\mid\mathbf{x}_{k - 1},\mathbf{u}_k)
    \prod_{k=1}^K\prod_{i=1}^N p(\mathbf{z}_{k_i}\mid\mathbf{x}_k,
    \mathbf{l}_i,\boldsymbol{\Theta}).
  \end{aligned}
\end{equation}

We may approximate \eqref{eqn:post_joint_factorized} with a normal distribution
whose moments $\boldsymbol{\mu}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ and
$\boldsymbol{\Sigma}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ have to be
estimated. To this end, we first derive a Maximum a Posteriori (MAP) estimator
for the mean

\begin{equation}\label{eqn:map_estimator}
  \begin{aligned}
  \hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}} &=
    \argmax_{\boldsymbol{\Theta},\mathcal{X},\mathcal{L}}
    p(\boldsymbol{\Theta}, \mathcal{X},\mathcal{L} \mid\mathcal{U},\mathcal{Z})
    \\
    &= \argmin_{\boldsymbol{\Theta},\mathcal{X},\mathcal{L}}-\log
    p(\boldsymbol{\Theta}, \mathcal{X},\mathcal{L} \mid\mathcal{U},\mathcal{Z}).
  \end{aligned}
\end{equation}

We further refine our problem by defining a \emph{motion} and \emph{observation}
model

\begin{equation}\label{eqn:process_model}
  \begin{aligned}
  \mathbf{x}_k &= \mathbf{h}(\mathbf{x}_{k-1}, \mathbf{u}_k, \mathbf{w}_k)\\
  \mathbf{z}_{k_i} &= \mathbf{g}(\mathbf{x}_{k}, \mathbf{l}_i,
    \boldsymbol{\Theta}, \mathbf{n}_k),
  \end{aligned}
\end{equation}

where

\begin{equation}\label{eqn:noise_model}
  \begin{aligned}
  \mathbf{w}_k \sim \mathcal{N}(\mathbf{0},\mathbf{Q}_k)\\
  \mathbf{n}_k \sim \mathcal{N}(\mathbf{0},\mathbf{R}_k)
  \end{aligned}
\end{equation}

are normally distributed process and observation noise variables,
$\mathbf{Q}_k$ and $\mathbf{R}_k$ being known covariance matrices. Although, the
functions $\mathbf{h}(\cdot)$ and $\mathbf{g}(\cdot)$ might be non-linear in
their parameters, we can approximate
$p(\mathbf{x}_k\mid\mathbf{x}_{k - 1},\mathbf{u}_k)$ and
$p(\mathbf{z}_{k_i}\mid\mathbf{x}_k, \mathbf{l}_i,\boldsymbol{\Theta})$ as
normal distributions through linearization.

\subsection{Least Squares Solution}

In case of linear motion and observation models, there exists a closed-form
solution to \eqref{eqn:map_estimator} based on the \emph{least squares} method
due to the normally distributed noise variables. In the other case, one can
resort to non-linear least squares methods that iteratively solve a linearized
version of the problem. In the following, we employ the \emph{Gauss-Newton}
algorithm for this purpose.

From \eqref{eqn:map_estimator} and the normal approximations, we can turn the
MAP problem into the minimization of a sum of quadratic functions. Non-linear
optimization techniques start with an initial guess
$\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ and refines
it iteratively with
$\delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ until
convergence.
$\delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ is
chosen in such a way that it minimizes a quadratic approximation of the
objective function around
$\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$.
Gauss-Newton method only requires the estimation of the Jacobian matrix
$\mathbf{H}$ of the objective function. If we stack up everything in block
matrix form, the update takes the form

\begin{equation}\label{eqn:dx_update}
  \begin{aligned}
  (\mathbf{H}^T\mathbf{T}^{-1}\mathbf{H})
    \delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}} &=
    -\mathbf{H}^T\mathbf{T}^{-1}\mathbf{e}(\mathbf{\hat{\boldsymbol{\mu}}_{
    \boldsymbol{\Theta}\mathcal{X}\mathcal{L}}}),
  \end{aligned}
\end{equation}

where $\mathbf{T}$ is formed with $\mathbf{Q}_k$ and $\mathbf{N}_k$, and
$\mathbf{e}(\mathbf{\hat{\boldsymbol{\mu}}_{
\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}})$ is the error of the current
estimate $\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$.

At convergence of the algorithm, the quantity
$\mathbf{H}^T\mathbf{T}^{-1}\mathbf{H}$ is the \emph{Fisher Information Matrix}
(FIM) and the inverse covariance matrix
$\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ of
our estimate
$\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$.

If we let $\mathbf{T}^{-1}=\mathbf{L}^T\mathbf{L}$ be the Cholesky
decomposition of the precision matrix, \eqref{eqn:dx_update} can be rewritten as

\begin{equation}\label{eqn:dx_update_normal}
  \begin{aligned}
  (\mathbf{L}\mathbf{H})^T(\mathbf{L}\mathbf{H})
    \delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}} &= 
    -(\mathbf{L}\mathbf{H})^T\mathbf{e}(\mathbf{\hat{\boldsymbol{\mu}}_{
    \boldsymbol{\Theta}\mathcal{X}\mathcal{L}}}),
  \end{aligned}
\end{equation}

which we can recognize as the \emph{normal equations} of the linear system

\begin{equation}\label{eqn:dx_update_standard}
  \begin{aligned}
  (\mathbf{L}\mathbf{H})
    \delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}} &=
    -\mathbf{e}(
    \mathbf{\hat{\boldsymbol{\mu}}_{
    \boldsymbol{\Theta}\mathcal{X}\mathcal{L}}}).
  \end{aligned}
\end{equation}

Thus, instead of directly solving \eqref{eqn:dx_update} which requires a
significant amount of computation and introduces numerical errors, we can take
advantage of matrix decompositions.

Let $\mathbf{L}\mathbf{H}$ be of size $m*n$ with the following thin
Singular Value Decomposition (\emph{SVD}) decomposition

\begin{equation}\label{eqn:svd_decomposition}
  \begin{aligned}
  \mathbf{L}\mathbf{H} &= \mathbf{U}_n\mathbf{S}_n\mathbf{V}_n^T,
  \end{aligned}
\end{equation}

where $\mathbf{U}_n$ is $m*n$, $\mathbf{S}_n=\diag(\sigma_1, \cdots, \sigma_n)$,
$\mathbf{V}_n$ is $n*n$, and $\sigma_i$ are the singular values of
$\mathbf{L}\mathbf{H}$.

From \eqref{eqn:svd_decomposition} and using the orthogonal property of
$\mathbf{U}_n$ and $\mathbf{V}_n$, we can solve \eqref{eqn:dx_update} as

\begin{equation}\label{eqn:dx_svd_solve}
  \begin{aligned}
  \delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}^
    {(SVD)} &=
    -\mathbf{V}_n\mathbf{S}_n^{-1}\mathbf{U}_n^T
    \mathbf{e}(
    \mathbf{\hat{\boldsymbol{\mu}}_{
    \boldsymbol{\Theta}\mathcal{X}\mathcal{L}}}).
  \end{aligned}
\end{equation}

Although useful for illustrating the concepts of our approach, the SVD
decomposition can be computationally demanding for large matrices. In practice,
we therefore use the thin \emph{QR} decomposition of $\mathbf{L}\mathbf{H}$

\begin{equation}\label{eqn:qr_decomposition}
  \begin{aligned}
  \mathbf{L}\mathbf{H}\boldsymbol{\Pi} &= \mathbf{Q}_n\mathbf{R}_n,
  \end{aligned}
\end{equation}

where $\boldsymbol{\Pi}$ is a permutation matrix, $\mathbf{Q}_n$ is $m*n$, and
$\mathbf{R}_n$ is $n*n$.

From \eqref{eqn:qr_decomposition} and using orthogonal property of
$\mathbf{Q}_n$, \eqref{eqn:dx_update} can be expressed as

\begin{equation}\label{eqn:dx_qr_solve}
  \begin{aligned}
  \mathbf{R}_n\boldsymbol{\Pi}^{T}
    \delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}^
    {(QR)}&=
    -\mathbf{Q}_n^T \mathbf{e}(
    \mathbf{\hat{\boldsymbol{\mu}}_{
    \boldsymbol{\Theta}\mathcal{X}\mathcal{L}}}),
  \end{aligned}
\end{equation}

which, due the upper triangular form of $\mathbf{R}_n$ can be easily solved by
\emph{back substitution}.

The $\mathbf{R}_n$ matrix can be used to compute the FIM and its
inverse the covariance estimate
$\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$. If we
drop the permutation matrix for clarity, the FIM becomes
$\mathbf{R}_n^T\mathbf{R}_n$. If we let
$\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ having
elements $\sigma_{ij}$ and $\mathbf{R}_n$ elements $r_{ij}$, there exists an
efficient algorithm for recovering any elements of the covariance estimate
without inverting the whole FIM

\begin{equation}\label{eqn:covariance_QR}
  \begin{aligned}
  \sigma_{ll} &= \frac{1}{r_{ll}}(\frac{1}{r_{ll}} -
    \sum_{j = l + 1, r_{lj}\neq 0}^n r_{lj}\sigma_{jl})\\
  \sigma_{il} &= \frac{1}{r_{ii}}
    (-\sum_{j = i + 1, r_{ij}\neq 0}^n r_{ij}\sigma_{jl} -
    \sum_{j = l + 1, r_{ij}\neq 0}^n r_{ij}\sigma_{lj}),
  \end{aligned}
\end{equation}

for $l=n,\cdots,1$, $i=l-1,\cdots,1$ and the lower part is given by symmetry.

At the convergence of the Gauss-Newton optimization, we are thus left with the
estimates $\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$
and $\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ of
the normal distribution $p(\boldsymbol{\Theta}, \mathcal{X},\mathcal{L}
\mid\mathcal{U},\mathcal{Z})$. In order to solve \eqref{eqn:post_calib}, we can
employ the marginalization property of normal
distributions~\cite{bishop06pattern}. If we express the estimates in the
partitioned form

\begin{equation}\label{eqn:partitioned_estimates}
  \begin{aligned}
  \hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}} &=
    \begin{pmatrix}
    \hat{\boldsymbol{\mu}}_{\mathcal{X}}\\
    \hat{\boldsymbol{\mu}}_{\mathcal{L}}\\
    \hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}}
    \end{pmatrix},
  \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}} &=
    \begin{pmatrix}
    \hat{\boldsymbol{\Sigma}}_{\mathcal{X}\mathcal{X}}&
    \hat{\boldsymbol{\Sigma}}_{\mathcal{X}\mathcal{L}}&
    \hat{\boldsymbol{\Sigma}}_{\mathcal{X}\boldsymbol{\Theta}}\\
    \hat{\boldsymbol{\Sigma}}_{\mathcal{L}\mathcal{X}}&
    \hat{\boldsymbol{\Sigma}}_{\mathcal{L}\mathcal{L}}&
    \hat{\boldsymbol{\Sigma}}_{\mathcal{L}\boldsymbol{\Theta}}\\
    \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{X}}&
    \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{L}}&
    \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\boldsymbol{\Theta}}\\
    \end{pmatrix},
  \end{aligned}
\end{equation}

then $p(\boldsymbol{\Theta}\mid\mathcal{U},\mathcal{Z})\sim\mathcal{N}
(\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}},
\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\boldsymbol{\Theta}})$. We can
thus extract $\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}}$ from
$\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ in no time,
and by placing $\boldsymbol{\Theta}$ to the right of the Jacobian matrix
$\mathbf{H}$ and using \eqref{eqn:covariance_QR},
$\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\boldsymbol{\Theta}}$ can be
computed in $\mathcal{O}(l)$, where $l=\card(\boldsymbol{\Theta})$.

\subsection{Truncated SVD and QR Solutions}

There exists a solution to \eqref{eqn:dx_update}
iff the FIM is invertible, i.e., it is \emph{full rank}. The rank of a
matrix is the maximum number of linearly independent column or row vectors. A
matrix with $m$ rows and $n$ columns has full rank when its rank is equal to
$\min(m,n)$. In real-world scenarios, where data is contaminated by noise, the
FIM might appear to be theoretically full rank although it is actually
\emph{rank deficient}. We can illustrate this with the matrix

\begin{equation}\label{eqn:rank_deficient_matrix}
  \begin{aligned}
    \mathbf{A} &=
    \begin{pmatrix}
    0.9999&1.9999&3.0014\\
    4.0007&5.0015&6.0007\\
    6.9998&8.0014&8.9988
    \end{pmatrix}.
  \end{aligned}
\end{equation}

Although being full rank, $\mathbf{A}$ was constructed from a rank deficient
matrix with added Gaussian noise. In the following, we will coin $\mathbf{A}$
a nearly rank deficient matrix. The issue of rank deficiency often appears in
robotics state estimation and is related to the problem of \emph{observability}
in the control theory.

Using SVD decomposition, we can identify a nearly rank deficient matrix by
analyzing its singular values. The \emph{numerical rank} $r$ of a matrix is
defined as the index of its smallest singular value $\sigma_r$ larger than
a user-defined tolerance $\epsilon$, i.e.,

\begin{equation}\label{eqn:numerical_rank}
  \begin{aligned}
  r &= \argmax_i \sigma_i\geq\epsilon.
  \end{aligned}
\end{equation}

From \eqref{eqn:dx_svd_solve}, we can see that if some of the $\sigma_i$ are
close to zero, i.e. $r<n$, the update vector
$\delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}^
{(SVD)}$ will be large and eventually lead to a divergence of the solution. In
order to cope with this issue, we can approximate $\mathbf{L}\mathbf{H}$ with a
lower rank matrix yielding the \emph{Truncated} SVD (TSVD) solution

\begin{equation}\label{eqn:dx_tsvd_solve}
  \begin{aligned}
  \delta\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}^
    {(TSVD)} &=
    -\mathbf{V}_r\mathbf{S}_r^{-1}\mathbf{U}_r^T
    \mathbf{e}(
    \mathbf{\hat{\boldsymbol{\mu}}_{
    \boldsymbol{\Theta}\mathcal{X}\mathcal{L}}}).
  \end{aligned}
\end{equation}

It is worth noting that TSVD applies a \emph{sharp} filter to the system,
whereas \emph{regularization} methods such as Tikhonov or ridge regression work
as a \emph{smooth} filter.

A similar approach can be derived using \emph{rank-revealing} QR decomposition
yielding to the Truncated QR (TQR) method.

\subsection{Selecting Informative Measurements}

Since we are mainly interested in calibrating our sensor and thus in the
posterior $p(\boldsymbol{\Theta}\mid\mathcal{U},\mathcal{Z})$, we do not need
to consider all measurements. Let us define a partition of the measurements
$\mathcal{D}_1=\{\mathbf{u}_{1:i}, \mathbf{z}_{1_{1:N}:i_{1:N}}\}$ and
$\mathcal{D}_2=\{\mathbf{u}_{i+1:K}, \mathbf{z}_{i+1_{1:N}:K_{1:N}}\}$ with
$i<K$. Using the information theory, we can quantify the information gain when
estimating $\boldsymbol{\Theta}$ with $\mathcal{D}_1$ alone or with
$\mathcal{D}_1$ and $\mathcal{D}_2$.

The \emph{mutual information} (MI) between two random variables $\mathbf{X}$ and
$\mathbf{Y}$ is defined as

\begin{equation}\label{eqn:mi_definition}
  \begin{aligned}
  I(\mathbf{X};\mathbf{Y}) &=
    \int_{\mathbf{X}}\int_{\mathbf{Y}}p(x, y)\log\frac{p(x,y)}{p(x)p(y)},
  \end{aligned}
\end{equation}

where $p(x, y)$ is the joint density of $\mathbf{X}$ and $\mathbf{Y}$, and
$p(x)$ and $p(x)$ their marginal densities. The MI measures the amount of
information $\mathbf{X}$ and $\mathbf{Y}$ share or, in other words, quantifies
the reduction of uncertainty in $\mathbf{X}$ when knowing $\mathbf{Y}$.

Before deriving the MI for our purpose, it is worth recalling another property
of normal distributions~\cite{bishop06pattern}. If we define
$\mathbf{\Theta}_1=\mathbf{\Theta}\mid\mathcal{D}_1$ and consider the joint
normal distribution $p(\mathbf{\Theta}_1,\mathcal{D}_2)$ with parameters

\begin{equation}\label{eqn:joint_normal}
  \begin{aligned}
  \boldsymbol{\mu}_{\boldsymbol{\Theta}_1\mathcal{D}_2} &=
    \begin{pmatrix}
    \boldsymbol{\mu}_{\boldsymbol{\Theta}_1}\\
    \boldsymbol{\mu}_{\mathcal{D}_2}\\
    \end{pmatrix},
  \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mathcal{D}_2} &=
    \begin{pmatrix}
    \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\boldsymbol{\Theta}_1}&
    \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mathcal{D}_2}\\
    \boldsymbol{\Sigma}_{\mathcal{D}_2\boldsymbol{\Theta}_1}&
    \boldsymbol{\Sigma}_{\mathcal{D}_2\mathcal{D}_2}
    \end{pmatrix},
  \end{aligned}
\end{equation}

then $p(\mathbf{\Theta}_1\mid\mathcal{D}_2)$ is a normal distribution with
parameters

\begin{equation}\label{eqn:joint_conditional}
  \begin{aligned}
  \boldsymbol{\mu}_{\boldsymbol{\Theta}_1\mid\mathcal{D}_2} &=
    \boldsymbol{\mu}_{\boldsymbol{\Theta}_1} +
    \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mathcal{D}_2}
    \boldsymbol{\Sigma}_{\mathcal{D}_2\mathcal{D}_2}^{-1}
    (\mathcal{D}_2 - \boldsymbol{\mu}_{\mathcal{D}_2})\\
  \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mid\mathcal{D}_2} &=
    \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\boldsymbol{\Theta}_1} -
    \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mathcal{D}_2}
    \boldsymbol{\Sigma}_{\mathcal{D}_2\mathcal{D}_2}^{-1}
    \boldsymbol{\Sigma}_{\mathcal{D}_2\boldsymbol{\Theta}_1}.
  \end{aligned}
\end{equation}

Furthermore, $\boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mid\mathcal{D}_2}$ can
be recognized as the \emph{Schur complement} of the joint covariance matrix
$\boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mathcal{D}_2}$.

The MI between $\mathbf{\Theta}_1$ and $\mathcal{D}_2$ can be computed as

\begin{equation}\label{eqn:mi_normal}
  \begin{aligned}
  I(\mathbf{\Theta}_1;\mathcal{D}_2) &=
    \mathbb{E}\left[\log
    \frac{p(\mathbf{\Theta}_1\mid\mathcal{D}_2)}{p(\mathbf{\Theta}_1)}\right]\\
    &= \frac{1}{2}\log\frac{|\boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1
    \boldsymbol{\Theta}_1}|}
    {|\boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\boldsymbol{\Theta}_1} -
    \boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mathcal{D}_2}
    \boldsymbol{\Sigma}_{\mathcal{D}_2\mathcal{D}_2}^{-1}
    \boldsymbol{\Sigma}_{\mathcal{D}_2\boldsymbol{\Theta}_1}|}\\
    &= \frac{1}{2}\log\frac{|\boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1
    \boldsymbol{\Theta}_1}|}
    {|\boldsymbol{\Sigma}_{\boldsymbol{\Theta}_1\mid\mathcal{D}_2}|},
  \end{aligned}
\end{equation}

where $|\cdot|$ is the matrix determinant.

Thus, using \eqref{eqn:mi_normal}, we can measure the amount of information
$\mathcal{D}_2$ conveys to our current estimate
$\boldsymbol{\Theta}\mid\mathcal{D}_1$.

\subsection{Implementation Details}

Thus far, we have delivered a formal introduction to the probabilistic
groundings of our self-supervised calibration approach. This section will be
dedicated to a practical online implementation of our algorithm.

The proposed calibration method is sketched in Alg.~\ref{alg:calibration}.
Defining $\mathcal{D}^{info}$ as the set of \emph{informative} measurements at
time $t$, we collect a measurement batch
$\mathcal{D}^{new}=\{\mathbf{u}_{t:t+k}, \mathbf{z}_{t_{1:N}:{t+k}_{1:N}}\}$
during $k$ timesteps and compute
$p(\mathbf{\Theta}\mid\mathcal{D}^{info},\mathcal{D}^{new})$ using Gauss-Newton
method with TQR updates. In a second step, if
$I(\mathbf{\Theta}\mid\mathcal{D}^{info};\mathcal{D}^{new})$ is larger
than a user-defined threshold $\theta$, $\mathcal{D}^{new}$ is added to
$\mathcal{D}^{info}$ and the estimate of $\mathbf{\Theta}$ is updated.

\begin{algorithm}[ht]
\caption{calibrateSensor()}
\label{alg:calibration}
\dontprintsemicolon
\SetKwComment{Comment}{// }{}
\KwIn{Initial guesses $\hat{\boldsymbol{\Theta}}^{(0)}$,
  $\hat{\mathbf{x}}_0^{(0)}$, $\hat{\mathcal{L}}^{(0)}$}
\KwIn{Motion $\mathbf{h}(\cdot)$ and observation $\mathbf{g}(\cdot)$ models}
\KwIn{Batch size $k$, TQR threshold $\epsilon$, MI threshold $\theta$}
\KwOut{$\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}}$ and
  $\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\boldsymbol{\Theta}}$}
\vskip 0.2cm
$\mathcal{D}^{info}\leftarrow\emptyset$ \;
$t\leftarrow1$ \;
\While {calibrate} {
  \Comment*[h]{Collecting measurements} \;
  $t^{init} \leftarrow t$ \;
  $\mathcal{D}^{new}\leftarrow\emptyset$ \;
  \While {$t < t^{init} + k$} {
    $\hat{\mathbf{x}}_t^{(0)} \leftarrow
      \mathbf{h}(\hat{\mathbf{x}}_{t-1}^{(0)},\mathbf{u}_t,\mathbf{0})$ \;
    $\mathcal{D}^{new}\leftarrow\mathcal{D}^{new}\cup\{\mathbf{u}_t,
      \mathbf{z}_{t_{1:N}}\}$ \;
    $t \leftarrow t + 1$ \;
  }
  \Comment*[h]{TQR minimization} \;
  $\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}} \leftarrow
    \argmax_{\boldsymbol{\Theta},\mathcal{X},\mathcal{L}}
    p(\boldsymbol{\Theta}, \mathcal{X},\mathcal{L} \mid\mathcal{D}^{info},
    \mathcal{D}^{new})$ \;
  \Comment*[h]{Marginalization} \;
  $\hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}}\leftarrow
    \hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ \;
  $\hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\boldsymbol{\Theta}}\leftarrow
    \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\mathcal{X}\mathcal{L}}$ \;
  \Comment*[h]{MI decision} \;
  \If {$I(\mathbf{\Theta}\mid\mathcal{D}^{info};\mathcal{D}^{new})>\theta$} {
    $\mathcal{D}^{info}\leftarrow\mathcal{D}^{info}\cup\mathcal{D}^{new}$ \;
    $\boldsymbol{\Theta}\sim\mathcal{N}(
      \hat{\boldsymbol{\mu}}_{\boldsymbol{\Theta}},
      \hat{\boldsymbol{\Sigma}}_{\boldsymbol{\Theta}\boldsymbol{\Theta}})$ \;
  }
}
\end{algorithm}

Our method has been fully implemented in MATLAB. Taking into account the
sparsity of the Jacobian matrix $\mathbf{H}$, the algorithmic complexity can
be largely reduced in terms of memory footprint and computation. To this end, we
have used the SuiteSparseQR package for performing TQR optimization.
