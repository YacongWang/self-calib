In order to evaluate and validate the approach proposed in this paper, we have
conducted experiments on simulated and real-world data. We shall first start
with the description of the experimental conditions and then demonstrate the
performance of our algorithm, along with some comparisons against existing
methods.

\subsection{Experimental Setup}

In our experiments, we consider the problem of a mobile robot moving on a plane.
Fig.~\ref{fig:exp_setup} depicts our experimental setup. The platform is
equipped with a range sensor delivering range and bearing angles measurements.
The calibration parameters of the range sensor consist in the transformation of
its coordinate system to the robot's coordinate system. The platform is further
endowed with wheel odometers outputting translational and rotational speeds.
While navigating on the plane, the robot observes a known number of landmarks
through its range sensor. Despite the apparent simplicity of the setup, our
algorithm is flexible enough to cope with more complex scenarios, e.g., multiple
heterogeneous sensors or 3D motion.

\begin{figure}[t]
\centering
\missingfigure[figwidth=\columnwidth]{Experimental setup.}
\caption{Experimental setup.}
\label{fig:exp_setup}
\end{figure}

More formally, we use the following motion and observation models

\begin{equation}\label{eqn:exp_model}
  \begin{aligned}
  \underbrace {
  \begin{pmatrix}
  x_k\\
  y_k\\
  \theta_k
  \end{pmatrix}}_{\mathbf{x}_k}&=
  \underbrace{
  \begin{pmatrix}
  x_{k-1}\\
  y_{k-1}\\
  \theta_{k-1}
  \end{pmatrix} + T
  \begin{pmatrix}
  \cos\theta_{k-1}&0\\
  \sin\theta_{k-1}&0\\
  0&1
  \end{pmatrix}
  \left(\begin{pmatrix}
  v_k\\
  w_k
  \end{pmatrix}
  + \mathbf{w}_k\right)
  }_{\mathbf{h}(\mathbf{x}_{k-1}, \mathbf{u}_k, \mathbf{w}_k)}\\
  a &= x_i - x_k - \delta_x\cos\theta_k + \delta_y\sin\theta_k\\
  b &= y_i - y_k - \delta_x\sin\theta_k - \delta_y\cos\theta_k\\
  \underbrace {
  \begin{pmatrix}
  r_k^i\\
  \phi_k^i
  \end{pmatrix} }_{\mathbf{z}_{k_i}}&=
  \underbrace {
  \begin{pmatrix}
  \sqrt{a^2 + b^2}\\
  \atan2(b, a) - \theta_k - \psi
  \end{pmatrix}
  + \mathbf{n}_k}_{\mathbf{g}(\mathbf{x}_{k}, \boldsymbol{\ell}_i,
    \boldsymbol{\Theta}, \mathbf{n}_k)},
  \end{aligned}
\end{equation}

\noindent where $\mathbf{x}_k=[x_k\;y_k\;\theta_k]^T$ denotes the robot pose at
timestep $k$, $T$ the sampling period, $\mathbf{u}_k=[v_k\;w_k]^T$ the measured
translational and rotational speeds, $\mathbf{z}_{k_i}=[r_k^i\;\phi_k^i]^T$ the
range and bearing observation of landmark $i$ with pose
$\boldsymbol{\ell}_i=[x_i\;y_i]^T$, $\mathbf{w}_k\sim\mathcal{N}(\mathbf{0},
\mathbf{Q}_k)$ with $\mathbf{Q}_k=\diag(\sigma^2_v,\sigma^2_w)$,
$\mathbf{n}_k\sim\mathcal{N}(\mathbf{0}, \mathbf{R}_k)$ with
$\mathbf{R}_k=\diag(\sigma^2_r,\sigma^2_\phi)$, and
$\mathbf{\Theta}=[\delta_x\;\delta_y\;\phi]^T$ the range sensor's calibration
parameters.

\subsection{Simulated Data}

In our simulation, we can generate various paths for the robot, along with
corresponding sensor measurements, and thus analyze the convergence of multiple
algorithms, especially in degenerate cases. We have created an environment
with $N=17$ landmarks uniformly distributed on a $10m\times 10m$ grid. We have
set the noise parameters empirically to $\sigma^2_v=4.4\times 10^{-3}$,
$\sigma^2_w=8.2\times 10^{-2}$, $\sigma^2_r=9.0036\times 10^{-4}$, and
$\sigma^2_\phi=6.7143\times 10^{-4}$. The calibration parameters are set to
$\delta_x=0.219$ [m], $\delta_y=0.1$ [m], and $\psi=\pi/4$ [rad].

In a first experiment, we have driven the robot along a straight path a $100$
times, maintaining identical initial conditions over the different runs, and
monitored the convergence of the calibration parameters.
Fig.~\ref{fig:straight_comp} shows the performance of different algorithms,
namely an Extended Kalman Filter (EKF) similar to~\cite{martinelli06automatic},
a standard batch non-linear least squares method without
regularization~\cite{kuemmerle11simultaneous}, and our TQR-MI approach.

\todo{more text to come discussing the results}

\begin{figure}[t]
\centering
\missingfigure[figwidth=\columnwidth]{A comparison of different algorithms.}
\caption{A comparison of different algorithms on a straight path.}
\label{fig:straight_comp}
\end{figure}

In a second step, we have run similar experiments as above, but with a loop
after the straight path. Fig.~\ref{fig:loop_comp} displays a comparison of the
different methods.

\todo{more text to come discussing the results}

\begin{figure}[t]
\centering
\missingfigure[figwidth=\columnwidth]{A comparison of different algorithms.}
\caption{A comparison of different algorithms on a well-behaved path.}
\label{fig:loop_comp}
\end{figure}

The last simulated experiment aims at analyzing the singular values, or the
diagonal elements of the $\mathbf{R}$ matrix, of the FIM.
Fig.~\ref{fig:sing_values} shows...
\todo{more text to come discussing the results}

\begin{figure}[t]
\centering
\missingfigure[figwidth=\columnwidth]{Singular values of the FIM.}
\caption{Singular values.}
\label{fig:sing_values}
\end{figure}

\subsection{Real-world Data}

In order to validate our method on real-world data, we have used the ``Lost in
the Woods Dataset'' provided with the courtesy of Tim Barfoot. This dataset
contains approximately $20$ minutes of a robot driving amongst a forest of
tubes which serve as landmarks. The ground truth comes from a motion capture
system that tracks robot motion and tube locations. Apart from the calibration
parameters, which are set to $\mathbf{\Theta}=[\delta_x=0.219\;\delta_y=0\;
\phi=0]^T$, the others remain unchanged.
